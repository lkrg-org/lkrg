// SPDX-License-Identifier: GPL-2.0-only
/*
 * Copyright (C) 2025 Ctrl IQ, Inc.
 * Author: Sultan Alsawaf <sultan@ciq.com>
 */
#ifndef _LKRG_ED_TASK_TREE_H_
#define _LKRG_ED_TASK_TREE_H_

struct p_ed_process {
	struct rb_node node;
	raw_spinlock_t lock;
	struct p_ed_process_task p_ed_task;
	struct rcu_head rcu;
};

int init_ed_task_cache(void);
void destroy_ed_task_cache(void);
struct p_ed_process *alloc_ed_task(struct task_struct *tsk);
void free_ed_task(struct p_ed_process *edp);
int ed_task_add(struct p_ed_process *edp);
int ed_task_del_current(void);

/*
 * The underscored functions shouldn't be used directly since they don't take
 * struct p_ed_process::lock, which can easily lead to forgetting to take the
 * lock in new code.
 */
struct p_ed_process *__ed_task_find_rcu(const struct task_struct *tsk);
struct p_ed_process *__ed_task_current(void);

/* Find and lock the current task's ed struct if found */
static inline struct p_ed_process *ed_task_lock_current(void)
{
	struct p_ed_process *edp = __ed_task_current();

	if (edp)
		raw_spin_lock(&edp->lock);

	return edp;
}

/* Find and trylock the current task's ed struct if found */
static inline struct p_ed_process *ed_task_trylock_current(void)
{
	struct p_ed_process *edp = __ed_task_current();

	return edp && raw_spin_trylock(&edp->lock) ? edp : NULL;
}

/*
 * Find and lock the specified task's ed struct if found. Must be called under
 * RCU read lock.
 */
static inline struct p_ed_process *
ed_task_find_lock_rcu(const struct task_struct *tsk)
{
	struct p_ed_process *edp = __ed_task_find_rcu(tsk);

	if (edp)
		raw_spin_lock(&edp->lock);

	return edp;
}

/* Unlock the ed task struct */
static inline void ed_task_unlock(struct p_ed_process *edp)
{
	raw_spin_unlock(&edp->lock);
}

#endif /* _LKRG_ED_TASK_TREE_H_ */

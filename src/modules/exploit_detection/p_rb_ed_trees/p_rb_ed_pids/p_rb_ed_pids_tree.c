/*
 * pi3's Linux kernel Runtime Guard
 *
 * Component:
 *  - Red-black tree for keeping track user-mode process pid structure
 *
 * Notes:
 *  - Make sence with own kmem_cache_* allocation
 *
 * Timeline:
 *  - Created: 07.IX.2017
 *
 * Author:
 *  - Adam 'pi3' Zabrocki (http://pi3.com.pl)
 *
 */

#include "../../../../p_lkrg_main.h"


struct kmem_cache *p_ed_pids_cache = NULL;
struct rb_root p_rb_hash[RB_HASH_SIZE] __attribute__ ((aligned(L1_CACHE_BYTES)));

DEFINE_SPINLOCK(p_rb_ed_pids_lock);

struct p_ed_process *p_rb_find_ed_pid(struct rb_root *p_root, pid_t p_arg) {

   struct rb_node *p_node = p_root->rb_node;
   struct p_ed_process *p_struct = NULL;
   struct p_ed_process *p_ret = NULL;

// STRONG_DEBUG - can be way too noisy
//   p_debug_log(P_LKRG_STRONG_DBG,
//          "Entering function <p_rb_find_ed_pid>\n");

//   spin_lock_irqsave(&p_rb_ed_pids_lock, p_flags);

   while(p_node) {
      p_struct = rb_entry(p_node, struct p_ed_process, p_rb);

      if (p_arg < p_struct->p_ed_task.p_pid) {
         p_node = p_node->rb_left;
      } else if (p_arg > p_struct->p_ed_task.p_pid) {
         p_node = p_node->rb_right;
      } else {
         p_ret = p_struct;
         goto p_rb_find_ed_pid_out;
      }
   }

p_rb_find_ed_pid_out:

// STRONG_DEBUG - can be way too noisy
//   p_debug_log(P_LKRG_STRONG_DBG,
//          "Leaving function <p_rb_find_ed_pid> (p_ret => 0x%lx)\n",(unsigned long)p_ret);

//   spin_unlock_irqrestore(&p_rb_ed_pids_lock, p_flags);

   return p_ret;
}


struct p_ed_process *p_rb_add_ed_pid(struct rb_root *p_root, pid_t p_arg, struct p_ed_process *p_source) {

   struct rb_node **p_node = &p_root->rb_node;
   struct rb_node *p_parent = NULL;
   struct p_ed_process *p_struct;
   struct p_ed_process *p_ret = NULL;

// STRONG_DEBUG
   p_debug_log(P_LKRG_STRONG_DBG,
          "Entering function <p_rb_add_ed_pid>\n");

   while(*p_node) {
      p_parent = *p_node;
      p_struct = rb_entry(p_parent, struct p_ed_process, p_rb);

      if (p_arg < p_struct->p_ed_task.p_pid) {
         p_node = &(*p_node)->rb_left;
      } else if (p_arg > p_struct->p_ed_task.p_pid) {
         p_node = &(*p_node)->rb_right;
      } else {
         p_ret = p_struct;
         goto p_rb_add_ed_pid_out;
      }

   }
   rb_link_node(&p_source->p_rb, p_parent, p_node);   // Insert this new node as a red leaf
   rb_insert_color(&p_source->p_rb, p_root);          // Rebalance the tree, finish inserting

p_rb_add_ed_pid_out:

// STRONG_DEBUG
   p_debug_log(P_LKRG_STRONG_DBG,
          "Leaving function <p_rb_add_ed_pid> (p_ret => 0x%lx)\n",(unsigned long)p_ret);

   return p_ret;
}


void p_rb_del_ed_pid(struct rb_root *p_root, struct p_ed_process *p_source) {

// STRONG_DEBUG
   p_debug_log(P_LKRG_STRONG_DBG,
          "Entering function <p_rb_del_ed_pid>\n");

   rb_erase(&p_source->p_rb, p_root);          // Erase the node
   p_reset_ed_flags(p_source);
   p_free_ed_pids(p_source);                   // Free the memory

// STRONG_DEBUG
   p_debug_log(P_LKRG_STRONG_DBG,
          "Leaving function <p_rb_del_ed_pid>\n");
}

static void p_ed_pids_cache_init(void *p_arg) {

   struct p_ed_process *p_struct = p_arg;

// STRONG_DEBUG
   p_debug_log(P_LKRG_STRONG_DBG,
          "Entering function <p_ed_pids_cache_init>\n");

   memset(p_struct, 0x0, sizeof(struct p_ed_process));

// STRONG_DEBUG
   p_debug_log(P_LKRG_STRONG_DBG,
          "Leaving function <p_ed_pids_cache_init>\n");
}

int p_init_rb_ed_pids(void) {

   int p_ret = P_LKRG_SUCCESS;
   unsigned int i;

// STRONG_DEBUG
   p_debug_log(P_LKRG_STRONG_DBG,
          "Entering function <p_init_rb_ed_pids>\n");

   for (i=0; i < RB_HASH_SIZE; i++) {
      p_rb_hash[i] = RB_ROOT;
   }

   if ( (p_ed_pids_cache = kmem_cache_create("p_ed_pids", sizeof(struct p_ed_process),
                                           0x0, SLAB_HWCACHE_ALIGN, p_ed_pids_cache_init)) == NULL) {
      p_print_log(P_LKRG_ERR, "kmem_cache_create() for ED PIDs error! :(\n");
      p_ret = -ENOMEM;
   }

// STRONG_DEBUG
   p_debug_log(P_LKRG_STRONG_DBG,
          "Leaving function <p_init_rb_ed_pids> (p_ret => %d)\n",p_ret);

   return p_ret;
}

void p_delete_rb_ed_pids(void) {

   struct rb_node *p_node;
   struct p_ed_process *p_tmp;
   unsigned long p_flags;
   unsigned int i;

// STRONG_DEBUG
   p_debug_log(P_LKRG_STRONG_DBG,
          "Entering function <p_delete_rb_ed_pids>\n");

   if (p_ed_pids_cache) {
      spin_lock_irqsave(&p_rb_ed_pids_lock, p_flags);
      for (i=0; i<RB_HASH_SIZE; i++) {
         for (p_node = rb_first(&p_rb_hash[i]); p_node; p_node = rb_next(p_node)) {
            p_tmp = rb_entry(p_node, struct p_ed_process, p_rb);
            p_print_log(P_LKRG_INFO, "Deleting ED PID => %d\n",p_tmp->p_ed_task.p_pid);
            p_free_ed_pids(p_tmp);
         }
      }
      kmem_cache_destroy(p_ed_pids_cache);
      p_ed_pids_cache = NULL;
      spin_unlock_irqrestore(&p_rb_ed_pids_lock, p_flags);
   }

// STRONG_DEBUG
   p_debug_log(P_LKRG_STRONG_DBG,
          "Leaving function <p_delete_rb_ed_pids>\n");
}
